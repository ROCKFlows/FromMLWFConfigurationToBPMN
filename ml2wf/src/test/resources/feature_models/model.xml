<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<extendedFeatureModel>
	<properties>
		<graphics key="showhiddenfeatures" value="true"/>
		<graphics key="legendautolayout" value="true"/>
		<graphics key="showshortnames" value="false"/>
		<graphics key="layout" value="horizontal"/>
		<graphics key="showcollapsedconstraints" value="true"/>
		<graphics key="legendhidden" value="false"/>
		<graphics key="layoutalgorithm" value="1"/>
	</properties>
	<struct>
		<and abstract="true" mandatory="true" name="AnomalyDetectionExploration">
			<and abstract="false" mandatory="true" name="AnomallyDetection">
				<and abstract="false" mandatory="false" name="References">
					<and abstract="true" mandatory="false" name="PHD">
						<feature abstract="false" mandatory="false" name="Benkabou2018">
							<description>@techreport{Benkabou2018,
								abstract = {La d{\'{e}}tection d'anomalies est une t{\^{a}}che cruciale qui a suscit{\'{e}} l'int{\'{e}}r{\^{e}}t de plusieurs travaux de recherche dans les communaut{\'{e}}s d'apprentissage automatique et fouille de donn{\'{e}}es. La complexit{\'{e}} de cette t{\^{a}}che d{\'{e}}pend de la nature des donn{\'{e}}es, de la disponibilit{\'{e}} de leur {\'{e}}tiquetage et du cadre applicatif dont elles s'inscrivent. Dans le cadre de cette th{\`{e}}se, nous nous int{\'{e}}ressons {\`{a}} cette probl{\'{e}}matique pour les donn{\'{e}}es complexes et particuli{\`{e}}rement pour les s{\'{e}}ries temporelles uni et multi-vari{\'{e}}es. Le terme &quot;anomalie&quot; peut d{\'{e}}signer une observation qui s'{\'{e}}carte des autres observations au point d'{\'{e}}veiller des soup{\c{c}}ons. De fa{\c{c}}on plus g{\'{e}}n{\'{e}}rale, la probl{\'{e}}matique sous-jacente (aussi appel{\'{e}}e d{\'{e}}tection de nouveaut{\'{e}}s ou d{\'{e}}tection des valeurs aberrantes) vise {\`{a}} identifier, dans un ensemble de donn{\'{e}}es, celles qui diff{\'{e}}rent significativement des autres, qui ne se conforment pas {\`{a}} un &quot;comportement attendu&quot; ({\`{a}} d{\'{e}}finir ou {\`{a}} apprendre automatiquement), et qui indiquent un processus de g{\'{e}}n{\'{e}}ration diff{\'{e}}rent. Les motifs &quot;anormaux&quot; ainsi d{\'{e}}tect{\'{e}}s se traduisent souvent par de l'information critique. Nous nous focalisons plus pr{\'{e}}cis{\'{e}}ment sur deux aspects particuliers de la d{\'{e}}tection d'anomalies {\`{a}} partir de s{\'{e}}ries temporelles dans un mode non-supervis{\'{e}}. Le premier est global et consiste {\`{a}} ressortir des s{\'{e}}ries relativement anormales par rapport une base enti{\`{e}}re. Le second est dit contextuel et vise {\`{a}} d{\'{e}}tecter localement, les points anormaux par rapport {\`{a}} la structure de la s{\'{e}}rie {\'{e}}tudi{\'{e}}e. Pour ce faire, nous proposons des approches d'optimisation {\`{a}} base de clustering pond{\'{e}}r{\'{e}} et de d{\'{e}}formation temporelle pour la d{\'{e}}tection globale ; et des m{\'{e}}canismes {\`{a}} base de mod{\'{e}}lisation matricielle pour la d{\'{e}}tection contextuelle. Enfin, nous pr{\'{e}}sentons une s{\'{e}}rie d'{\'{e}}tudes empiriques sur des donn{\'{e}}es publiques pour valider les approches propos{\'{e}}es et les comparer avec d'autres approches connues dans la litt{\'{e}}rature. De plus, une validation exp{\'{e}}rimentale est fournie sur un probl{\`{e}}me r{\'{e}}el, concernant la d{\'{e}}tection de s{\'{e}}ries de prix aberrants sur les pneumatiques, pour r{\'{e}}pondre aux besoins exprim{\'{e}}s par le partenaire industriel de cette th{\`{e}}se},
								author = {Benkabou, Seif-Eddine},
								keywords = {Apprentissage automatique,Math{\'{e}}matiques appliqu{\'{e}}es},
								month = {mar},
								publisher = {Universit{\'{e}} de Lyon},
								title = {{D{\'{e}}tection d'anomalies dans les s{\'{e}}ries temporelles : application aux masses de donn{\'{e}}es sur les pneumatiques}},
								url = {https://tel.archives-ouvertes.fr/tel-01839074},
								year = {2018}
								}
							</description>
						</feature>
					</and>
					<and abstract="false" mandatory="false" name="DataScientist">
						<feature abstract="false" mandatory="false" name="Yassine"/>
					</and>
				</and>
				<and abstract="false" mandatory="true" name="Criteria">
					<and abstract="true" mandatory="true" name="DatasetCriteria">
						<and abstract="true" mandatory="false" name="DataStructuration">
							<and abstract="false" mandatory="false" name="TimeSeries">
								<feature abstract="false" mandatory="false" name="PeriodicData"/>
							</and>
						</and>
						<feature abstract="true" mandatory="false" name="ValidationDataSetCriteria"/>
					</and>
					<and abstract="true" mandatory="false" name="Requirement">
						<feature abstract="true" mandatory="false" name="TimeComplexity"/>
						<feature abstract="false" mandatory="false" name="Stability"/>
					</and>
					<feature abstract="true" mandatory="false" name="HumanInteractionCriteria"/>
				</and>
				<and abstract="true" mandatory="false" name="Steps">
					<and abstract="true" mandatory="false" name="tools">
						<and abstract="true" mandatory="false" name="loss function">
							<feature abstract="false" mandatory="false" name="Mean Absolute Error">
								<description>Mean Absolute Error (MAE)
									Measures average/mean squared error of our predictions.
									MAE = \Sigma_{i=1}^{n}\frac{|\hat{y}_i - y_i|}{n}
									Gives less weight to the outliers, when you are sure that they are outliers prefer MAE to MSE.
								</description>
							</feature>
							<feature abstract="false" mandatory="false" name="Mean Square Error">
								<description>Mean Squared Error (MSE)
									Incorporates both the variance and the bias of the predictor.
									MSE = \Sigma_{i=1}^{n}{\frac{(\hat{y_i} - y_i)^2}{n}}
									When you have unexpected values that you should take into account use MSE instead of MAE.
								</description>
							</feature>
						</and>
						<feature abstract="true" mandatory="false" name="testStability"/>
					</and>
					<and abstract="true" mandatory="false" name="Training_step">
						<feature abstract="false" mandatory="false" name="train OC_SVM"/>
					</and>
					<and abstract="true" mandatory="false" name="SelectObservationToLabel_Step">
						<feature abstract="true" mandatory="false" name="RefineModel_step"/>
					</and>
					<and abstract="true" mandatory="false" name="Labeling_Step">
						<feature abstract="true" mandatory="false" name="HumanLabelling_Step"/>
					</and>
					<and abstract="true" mandatory="false" name="Preprocessing_Step">
						<feature abstract="true" mandatory="false" name="preprocess data_Step"/>
						<feature abstract="false" mandatory="false" name="compute descriptors_Step"/>
					</and>
				</and>
				<and abstract="true" mandatory="false" name="Methods">
					<feature abstract="false" mandatory="false" name="prioritize anomalies"/>
					<feature abstract="false" mandatory="false" name="ensureStability"/>
				</and>
				<and abstract="true" mandatory="false" name="ReferenceToWorkflows">
					<feature abstract="true" mandatory="false" name="ReferenceToInstanceWorkflows"/>
					<feature abstract="true" mandatory="false" name="ReferenceToMetaWorkflow"/>
				</and>
			</and>
		</and>
	</struct>
	<constraints>
		<rule>
			<description>To be review</description>
			<imp>
				<conj>
					<var>OC_SVM</var>
					<var>Benkabou2018</var>
				</conj>
				<var>OnlyNormalTimeSeriesInTrainingSet_Criteria</var>
			</imp>
		</rule>
		<rule>
			<imp>
				<conj>
					<var>Yassine</var>
					<var>OC_SVM</var>
				</conj>
				<var>fewAnomaliesInTrainsingSet_Criteria</var>
			</imp>
		</rule>
	</constraints>
</extendedFeatureModel>
